{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597180381216",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pickle\n",
    "import seaborn\n",
    "import json  \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.set()\n",
    "SAVE_FIGS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model-Dataset Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model-data results\n",
    "raw = pd.read_pickle(r'Output\\combination_results.pkl')\n",
    "raw['Base_model'] = raw.apply(lambda x: x['Model'].split('_')[0], axis=1)\n",
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coverage vs Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all model-data combination as corr vs coverage\n",
    "plt.scatter(raw['Coverage'],raw['Avg-R'])\n",
    "plt.ylabel('Correlation')\n",
    "plt.xlabel('Coverage')\n",
    "if SAVE_FIGS: plt.savefig('Figures\\Summary\\All_Corr_Cov.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot effect of model parameter as corr vs coverage\n",
    "data = raw[raw['Data'] == 'Daily']\n",
    "AgglomerativeClustering = data[data['Base_model'] == 'AgglomerativeClustering'][['Coverage','Avg-R']]\n",
    "DBSCAN = data[data['Base_model'] == 'DBSCAN'][['Coverage','Avg-R']]\n",
    "KMeans = data[data['Base_model'] == 'KMeans'][['Coverage','Avg-R']]\n",
    "AffinityPropagation = data[data['Base_model'] == 'AffinityPropagation'][['Coverage','Avg-R']]\n",
    "\n",
    "plt.plot(DBSCAN['Coverage'],DBSCAN['Avg-R'])\n",
    "plt.plot(AgglomerativeClustering['Coverage'],AgglomerativeClustering['Avg-R'])\n",
    "plt.plot(KMeans['Coverage'],KMeans['Avg-R'])\n",
    "plt.scatter(AffinityPropagation['Coverage'],AffinityPropagation['Avg-R'])\n",
    "plt.legend(['DBSCAN','AgglomerativeClustering','KMeans','AffinityPropagation'])\n",
    "plt.ylabel('Correlation')\n",
    "plt.xlabel('Coverage')\n",
    "if SAVE_FIGS: plt.savefig('Figures\\Summary\\Model_Corr_Cov.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot all combination according to base model\n",
    "colors = {'AgglomerativeClustering':'green', 'DBSCAN':'blue','AffinityPropagation':'red','KMeans':'purple'}\n",
    "\n",
    "legend_elements = [ Line2D([0], [0], marker='o', color='w', label='Scatter', markerfacecolor=color, markersize=10) for color in colors.values() ]\n",
    "        \n",
    "plt.scatter(raw['Coverage'],raw['Avg-R'], c=[colors[model] for model in raw['Base_model']])\n",
    "plt.ylabel('Correlation')\n",
    "plt.xlabel('Coverage')\n",
    "plt.legend(legend_elements,colors.keys())\n",
    "if SAVE_FIGS: plt.savefig('Figures\\Summary\\All_models_Corr_Cov.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis - Best Correlation Per Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get best model for each data set\n",
    "maxs = raw[raw['Coverage'] > .5][['Data','Avg-R']]\n",
    "maxs = maxs.groupby('Data').agg('max')\n",
    "bests = pd.merge(raw,maxs,on=['Avg-R','Data'])\n",
    "bests = bests.sort_values('Avg-R', ascending = False)[['Avg-R','Coverage','Data','Model']]\n",
    "bests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all clusters from all combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load all clusters\n",
    "all_clusters = pd.DataFrame(columns=['Corr','Cluster'])\n",
    "for subdir, dirs, files in os.walk('Output\\Correlations'):\n",
    "    for file in files:\n",
    "\n",
    "        # for all files open both correlation and cluster, create and stack df\n",
    "        with open('Output\\Correlations\\\\'+file, 'r') as fp:\n",
    "            correlations = json.load(fp)\n",
    "        with open('Output\\Clusters\\\\'+file, 'r') as fp:\n",
    "            clusters = json.load(fp)\n",
    "\n",
    "        clusters_df = pd.DataFrame.from_dict(correlations, orient='index')\n",
    "        clusters_df = clusters_df.reset_index().rename(columns= {'index':'key',0:'Corr'})\n",
    "        clusters_df['Cluster'] = clusters_df.apply(lambda x: clusters[x['key']],axis=1)\n",
    "        clusters_df['Cluster_len'] = clusters_df.apply(lambda x: len(x['Cluster']), axis = 1)\n",
    "        clusters_df['File'] = file\n",
    "        clusters_df = clusters_df.drop('key', axis = 1)\n",
    "        all_clusters = all_clusters.append(clusters_df)\n",
    "\n",
    "all_clusters\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notable clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get highly correlated cluster from all models and data\n",
    "notable_clusters = all_clusters[all_clusters.Cluster_len > 3]\n",
    "notable_clusters = notable_clusters[notable_clusters.Corr > .95]\n",
    "notable_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ALK, DAL, LUV, UAL]\tall airlines - with out using GICS\n",
    "# [CCL, MGM, NCLH, RCL] cruises and resorts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model-Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top cluster for top Model-Data combo\n",
    "notable_clusters = all_clusters[all_clusters.File == 'AgglomerativeClustering_250_Daily+Weekly.json']\n",
    "notable_clusters = notable_clusters[notable_clusters.Corr > .95]\n",
    "notable_clusters = notable_clusters[notable_clusters.Cluster_len >= 3] # for nice visualizations\n",
    "notable_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get time series data for clusters\n",
    "ClustersVis = list(notable_clusters['Cluster'])\n",
    "start = datetime(2019,11,1)\n",
    "end = datetime(2020,8,1)\n",
    "results = [yf.download(ClusterVis, start= start, end= end ,interval = '1d',prepost = True,threads = False)['Close'] for ClusterVis in ClustersVis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Clusters time series data\n",
    "for result in results:\n",
    "    plt.title(', '.join(result.columns) + ' Daily Close')    \n",
    "    plt.plot(result)\n",
    "    plt.xticks(rotation=25)\n",
    "    plt.legend(result.columns)\n",
    "    if SAVE_FIGS: plt.savefig('Figures\\Top_Model\\\\' + '_'.join(result.columns) + '_DailyClose.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# view GISC of clusters\n",
    "GICS = pd.read_csv('Data\\GICS-wiki.csv',encoding='ANSI').set_index('Stock', drop =True)\n",
    "for result in results:\n",
    "    print(GICS[GICS.index.isin(result.columns)][['GICS Sector','GICS Sub Industry']])"
   ]
  }
 ]
}